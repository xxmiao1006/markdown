## 题目

### java

**1.String、StringBuffer 和 StringBuilder 的区别?**

​		String 不可变，StringBuffer 和 StringBuilder 可变

​		StringBuffer和StringBulider都是用来拼接字符串的，StringBulider不是线程安全的，StringBuffer是线程安全的（StringBuffer对操作方法都加上了synchronize关键字）。



**2.String 的内部实现?String 对象主要存储在哪块区域?**

​		JDK8 中内部实现实际上是一个char[] 数组。value 数组被声明为 final，这意味着 value 数组初始化之后就不能再引用其它数组。并且 String 内部没有改变 value 数组的方法，因此可以保证 String 不可变。

```java
//数组定义为常量，不可修改 
private final char value[];
```

​		在 Java 9 之后，String 类的实现改用 byte 数组存储字符串，同时使用 `coder` 来标识使用了哪种编码

```java
public final class String
    implements java.io.Serializable, Comparable<String>, CharSequence {
    /** The value is used for character storage. */
    private final byte[] value;

    /** The identifier of the encoding used to encode the bytes in {@code value}. */
    private final byte coder;
}
```

​		在JDK1.7之前，StringPool被放在运行时常量池，所以属于永久代，在1.7之后被移到了堆中，因为永久代空间有限，容易引发OOM。



**3.String为什么要声明成final类？（不可变的好处？）**

* 可以缓存 hash 值

因为 String 的 hash 值经常被使用，例如 String 用做 HashMap 的 key。不可变的特性可以使得 hash 值也不可变，因此只需要进行一次计算。

* String Pool 的需要

如果一个 String 对象已经被创建过了，那么就会从 String Pool 中取得引用。只有 String 是不可变的，才可能使用 String Pool。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191210004132894.png"/> </div><br>
* 安全性

String 经常作为参数，String 不可变性可以保证参数不可变。例如在作为网络连接参数的情况下如果 String 是可变的，那么在网络连接过程中，String 被改变，改变 String 的那一方以为现在连接的是其它主机，而实际情况却不一定是。

* 线程安全  

String 不可变性天生具备线程安全，可以在多个线程中安全地使用。



**4.HashMap 和 HashSet 的区别？HashSet是怎么实现的？**

HashMap最顶层实现的是Map接口，HashSet最顶层实现的是Collection接口；Map接口一般存放的是键值对，而Collection接口存放的是单一元素；HashMap是用键来计算hash值判断元素是否重复，HashSet使用值对象来计算hash值

HashSet的底层实际就是使用的HashMap,将值对象当作HashMap的key（不可重复），值对象为同一对象。

```java
public class HashSet<E>
    extends AbstractSet<E>
    implements Set<E>, Cloneable, java.io.Serializable
{

    private transient HashMap<E,Object> map;

    // Dummy value to associate with an Object in the backing Map
    private static final Object PRESENT = new Object();
    
    public boolean add(E e) {
        return map.put(e, PRESENT)==null;
    }
```



**5.HashMap、HashTable 和 ConcurrentHashMap 的区别**

HashMap是线程不安全的，HashTable(Synchronized)和ConcurrentHashMap(1.8之前使用分段锁，1.8并发控制使用Synchronized和CAS来操作) 是线程安全的

HashMap和ConcurrentHashMap是Map接口的实现，HashTable是基于Dictionary抽象类

HashMap允许空（null）键值（key）而Hashtable、ConcurrentHashMap 不允许





**6.Map的接口实现**

HashMap,TreeMap,LinkedHashMap,hashtable

Map主要用于存储健值对，根据键得到值，因此不允许键重复(重复了覆盖了),但允许值重复。
Hashmap 是一个最常用的Map,它根据键的HashCode值存储数据,根据键可以直接获取它的值，具有很快的访问速度，遍历时，取得数据的顺序是完全随机的。 HashMap最多只允许一条记录的键为Null;允许多条记录的值为 Null;HashMap不支持线程的同步，即任一时刻可以有多个线程同时写HashMap;可能会导致数据的不一致。如果需要同步，可以用 Collections的synchronizedMap方法使HashMap具有同步的能力，或者使用ConcurrentHashMap。

Hashtable与 HashMap类似,它继承自Dictionary类，不同的是:它不允许记录的键或者值为空;它支持线程的同步，即任一时刻只有一个线程能写Hashtable,因此也导致了 Hashtable在写入时会比较慢。

LinkedHashMap 是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的.也可以在构造时用带参数，按照应用次数排序。在遍历的时候会比HashMap慢，不过有种情况例外，当HashMap容量很大，实际数据较少时，遍历起来可能会比 LinkedHashMap慢，因为LinkedHashMap的遍历速度只和实际数据有关，和容量无关，而HashMap的遍历速度和他的容量有关。

TreeMap实现SortMap接口，能够把它保存的记录根据键排序,默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator 遍历TreeMap时，得到的记录是排过序的。

一般情况下，我们用的最多的是HashMap,在Map 中插入、删除和定位元素，HashMap 是最好的选择。但如果您要按自然顺序或自定义顺序遍历键，那么TreeMap会更好。如果需要输出的顺序和输入的相同,那么用LinkedHashMap 可以实现,它还可以按读取顺序来排列.

HashMap是一个最常用的Map，它根据键的hashCode值存储数据，根据键可以直接获取它的值，具有很快的访问速度。HashMap最多只允许一条记录的键为NULL，允许多条记录的值为NULL。

HashMap不支持线程同步，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致性。如果需要同步，可以用Collections的synchronizedMap方法使HashMap具有同步的能力。

Hashtable与HashMap类似，不同的是：它不允许记录的键或者值为空；它支持线程的同步，即任一时刻只有一个线程能写Hashtable，因此也导致了Hashtable在写入时会比较慢。

LinkedHashMap保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的。

在遍历的时候会比HashMap慢TreeMap能够把它保存的记录根据键排序，默认是按升序排序，也可以指定排序的比较器。当用Iterator遍历TreeMap时，得到的记录是排过序的。



**7.LinkedHashMap的实现机制**

LinkedHashMap继承自HashMap，它的多种操作都是建立在HashMap操作的基础上的。同HashMap不同的是，**LinkedHashMap维护了一个Entry的双向链表，保证了插入的Entry中的顺序**。

LinkedHashMap里面的entry继承了HashMap的entry，并且增加了双向指针

```java
static class Entry<K,V> extends HashMap.Node<K,V> {
    Entry<K,V> before, after;
    Entry(int hash, K key, V value, Node<K,V> next) {
        super(hash, key, value, next);
    }
}

	/**
	* 头指针，指向第一个node
	*/
	transient LinkedHashMap.Entry<K,V> head;

    /**
     * 尾指针，指向最后一个node
     */
    transient LinkedHashMap.Entry<K,V> tail;

    /**
     * 一个条件变量，它控制了是否在get操作后需要将新的get的节点重新放到链表的尾部
     * LinkedHashMap可以维持了插入的顺序，但是这个顺序不是不变的，可以被get操作打乱。
     *
     * @serial
     */
    final boolean accessOrder;

```

[超详细LinkedHashMap解析](https://blog.csdn.net/qq_40050586/article/details/105851970)





**8.创建对象的过程**

* 检查类是否被加载
* 为对象分配内存（**类加载完成以后**，虚**拟机就开始为对象分配内存**，此时所需内存的**大小就已经确定**了。只需要在堆上分配所需要的内存即可）
* 为分配的内存空间初始化零值（将对象的内存空间都初**始化为零值**，这样能**保证对象即使没有赋初值，也可以直接使用**）
* 对对象进行其他的设置（**设置的地方都在对象头中**，包括这个**对象所属的类，类的元数据信息，对象的hashcode，GC分代年龄**等信息）
* 执行init方法

创建对象的几种方式：

* 使用new关键字

* Class对象的newInstance()方法

* 构造函数对象的newInstance()方法

* 对象反序列化

* Object对象的clone()方法
* 使用Unsafe类创建对象

在创建对象的过程中，jvm会首先去元空间检查是否有这个类的信息，如果没有则执行类的加载过程，有的话则创建对象。

对象的创建过程中，（**在为这些实例变量分配内存的同时，这些实例变量也会被赋予默认值(零值)。**）初始化顺序：

父类静态变量/父类静态方法块-> 子类静态变量/子类静态代码块->父类成员变量/方法块->父类构造函数->子类成员变量/方法快->子类构造函数

小结：创建一个对象包含下面两个过程：

1、类构造器完成类初始化（分配内存、赋予默认值）

2、类实例化（赋予给定值）

[Java 中创建一个对象的过程？](https://www.cnblogs.com/JonaLin/p/12674281.html)



**9.判断一个对象是否被回收**

判断对象是否被回收一般有两种算法，引用技术法和可达性分析算法，引用计数法无法解决对象循环引用的问题，因此java里面判断对象是否能被回收采用的是可达性分析算法。

可达性分析算法:以GC Roots为起点，可达的都是存活的，不可达的都是需要被回收的。在java中能作为GC Roots的一般是：

- 虚拟机栈中局部变量表中引用的对象
- 本地方法栈中 JNI 中引用的对象
- 方法区中类静态属性引用的对象
- 方法区中的常量引用的对象



**10.新生代和老年代用的垃圾回收策略？**

垃圾回收策略一般有一下几种：标记-清除（标记和清除过程效率都不高，而且会产生内存碎片），标记-整理（需要移动大对象，但是不会产生内存碎片），复制-清除（内存使用率低）。所以一般而言针对不同代采用不同的算法。

- 新生代使用：复制算法
- 老年代使用：标记 - 清除 或者 标记 - 整理 算法



**11.强引用、弱引用、软引用和虚引用的区别**

被强引用关联的对象不会被回收。

被软引用关联的对象只有在内存不够的情况下才会被回收。

被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。

虚引用又称为幽灵引用或者幻影引用，一个对象是否有虚引用的存在，不会对其生存时间造成影响，也无法通过虚引用得到一个对象。



**12.final 关键字的作用，final 在多线程并发条件下的作用**

- 对于基本类型，final 使数值不变；
- 对于引用类型，final 使引用不变，也就不能引用其它对象，但是被引用的对象本身是可以修改的。
- 声明方法不能被子类重写。
- 声明类不允许被继承。

final 在多线程并发条件下的作用原理是通过禁止cpu的指令集重排序

1. 在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。
2. 初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。

在Java语言里面（特指JDK 5以后，即Java内存模型被修正之后的Java语言），不可变（Immutable）的对象一定是线程安全的，无论是对象的方法实现还是方法的调用者，都不需要再进行任何线程安全保障措施。

多线程共享的数据是一个基本数据类型，那么只要在定义时使用final关键字修饰它就可以保证它是不可变的。如果共享数据是一个对象，由于Java语言目前暂时还没有提供值类型的支持，那就需要对象自行保证其行为不会对其状态产生任何影响才行

[多线程与高并发(五)final关键字](https://www.cnblogs.com/yuanqinnan/p/11231274.html)



**13.synchronized 作用于不同方法和代码块的区别**

修饰方法，方法标识ACC_PUBLIC代表public修饰，ACC_SYNCHRONIZED指明该方法为同步方法

修饰同步代码块，生成monitor指令。执行monitorenter指令，退出同步代码块，执行monitorexit指令，可以看到有2个monitorexit指令，第一个是正常退出执行的，第二个是当异常发生时执行的

* 修饰实例方法，对当前实例对象this加锁

* 修饰静态方法，对当前类的Class对象加锁

* 修饰代码块，指定加锁对象，对给定对象加锁



**14.volatile和synchronized的区别**

* volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取； synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。
* volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的
* volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性
* volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。
* volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化
  



**15.哪些方法可以创建线程池**

Executors.newSingleThreadExecutor()  单个线程

Executors.newFixedThreadPool(5) 创建一个固定大小的线程池

Executors.newCachedThreadPool() 创建一个可伸缩的线程池

以上几种方法不推荐，推荐使用ThreadPoolExecutor，上面几个方法底层也是使用ThreadPoolExecutor，只不过参数配置不同，使用ThreadPoolExecutor可以手动设置参数，更加了解线程池的原理和运行机制

```java
public ThreadPoolExecutor(int corePoolSize, //核心线程池大小
                          int maximumPoolSize, //最大线程池大小
                          long keepAliveTime, //非核心线程资源多长时间没人访问释放
                          TimeUnit unit, //时间单位
                          BlockingQueue<Runnable> workQueue,//阻塞队列
                          ThreadFactory threadFactory, //线程工程，一般用默认的
                          RejectedExecutionHandler handler //拒绝策略，当线程池达到最大并且阻塞队列满的拒绝策略
                         ) 
```



**16.数组和链表的区别**

​	数组	链表

* 逻辑结构	（1）数组在内存中连续； (2)使用数组之前，必须事先固定数组长度，不支持动态改变数组大小；(3) 数组元素增加时，有可能会数组越界；(4) 数组元素减少时，会造成内存浪费；（5）数组增删时需要移动其它元素	；（1）链表采用动态内存分配的方式，在内存中不连续 (2)支持动态增加或者删除元素 (3)需要时可以使用malloc或者new来申请内存，不用时使用free或者delete来释放内存

* 内存结构	数组从栈上分配内存，使用方便，但是自由度小	；链表从堆上分配内存，自由度大，但是要注意内存泄漏
* 访问效率	数组在内存中顺序存储，可通过下标访问，访问效率高	；链表访问效率低，如果想要访问某个元素，需要从头遍历
* 越界问题	数组的大小是固定的，所以存在访问越界的风险；	只要可以申请得到链表空间，链表就无越界风险



**17.深拷贝和浅拷贝**

浅拷贝：拷贝对象和原始对象的引用类型引用同一个对象。

深拷贝：拷贝对象和原始对象的引用类型引用不同对象。

[面试题：深拷贝和浅拷贝(超级详细，有内存图)](https://blog.csdn.net/jiang7701037/article/details/98738487)



**18.jvm中，直接内存是什么**

直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是《Java虚拟机规范》中定义的内存区域（对外内存）

在JDK 1.4中新加入了NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作。

自从 JDK 引入 NIO 后，直接内存的使用也越来越普遍。通过 native 方法可以分配堆外内存，通过 DirectByteBuffer 对象来操作。

可以通过 **-XX:MaxDirectMemorySize** 参数来设置最大可用直接内存，如果启动时未设置则默认为最大堆内存大小，即与 -Xmx 相同。即假如最大堆内存为1G，则默认直接内存也为1G，那么 JVM 最大需要的内存大小为2G多一些。当直接内存达到最大限制时就会触发GC，如果回收失败则会引起OutOfMemoryError。



**19.final，finalize， finally有什么区别**

final是修饰符（关键字），修饰的类不能派生新的子类，将变量声明为final,可以保证他们使用中引用不被改变，将方法声明为final，则不能被重写。

finalize则是一个方法名，定义在最顶层的Object类中，这个方法在gc启动，该对象被回收的时候被调用。

finally作为异常处理的一部分，它只能用在try/catch语句中，并且附带一个语句块，表示这段语句最终一定会被执行（不管有没有抛出异常），经常被用在需要释放资源的情况下。







### 操作系统

**1.线程的生命周期**

线程的生命周期包含5个阶段，包括：新建、就绪、运行、阻塞、销毁。

- 新建：就是刚使用new方法，new出来的线程；
- 就绪：就是调用的线程的start()方法后，这时候线程处于等待CPU分配资源阶段，谁先抢的CPU资源，谁开始执行;
- 运行：当就绪的线程被调度并获得CPU资源时，便进入运行状态，run方法定义了线程的操作和功能;
- 阻塞：在运行状态的时候，可能因为某些原因导致运行状态的线程变成了阻塞状态，比如sleep()、wait()之后线程就处于了阻塞状态，这个时候需要其他机制将处于阻塞状态的线程唤醒，比如调用notify或者notifyAll()方法。唤醒的线程不会立刻执行run方法，它们要再次等待CPU分配资源进入运行状态;
- 销毁：如果线程正常执行完毕后或线程被提前强制性的终止或出现异常导致结束，那么线程就要被销毁，释放资源;



**2.sleep和wait的区别**

sleep是属于Thread类的**静态**方法，而wait是Object类的**实例**方法；

sleep,wait调用后都会暂停当前线程并让出cpu的执行时间，但不同的是sleep不会释放当前持有的对象的锁资源，到时间后会继续执行，而wait会放弃所有锁并需要notify/notifyAll后重新获取到对象锁资源后才能继续执行

它们都可以被interrupted方法中断。

另外值得一提的是Thread.Sleep(0)的作用，就是触发操作系统立刻重新进行一次CPU竞争，竞争的结果也许是当前线程仍然获得CPU控制权，也许会换成别的线程获得CPU控制权



**3.死锁产生的原因**

* 因为系统资源不足。
* 进程运行推进的顺序不合适。
* 资源分配不当等。

产生死锁的四个必要条件：

* 互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用。
* 请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放。
* 不剥夺条件：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放。
* 环路等待条件：在发生死锁时，必然存在一个进程--资源的环形链。

预防死锁

* 资源一次性分配：一次性分配所有资源，这样就不会再有请求了：（破坏请求条件）
* 只要有一个资源得不到分配，也不给这个进程分配其他的资源：（破坏保持条件）
* 可剥夺资源：即当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源（破坏不可剥夺条件）
* 资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破坏环路等待条件）



**4.在 Linux 系统下，有哪些进程调度的方式**

* 先来先服务 first-come first-serverd（FCFS）

非抢占式的调度算法，按照请求的顺序进行调度。

有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

* 短作业优先 shortest job first（SJF）

非抢占式的调度算法，按估计运行时间最短的顺序进行调度。

长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

* 最短剩余时间优先 shortest remaining time next（SRTN）

最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

* 时间片轮转

将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

linux进程分为实时进程（有实时需求的进程）和普通进程两种，实时进程的优先级高于普通进程，故优先执行实时进程。

实时进程的调度方式： 静态优先级策略+先进先出策略/轮转策略
系统调度时，首先执行静态优先级策略，会根据用户设定的静态优先级对实时进程进行排序，先执行优先级高的进程直到完毕，再执行优先级低的进程。当有数个实时进程的优先级相同时，有先进先出策略（SCHED_FIFO）和轮转策略（SCHED_RR）供用户选择。若为先进先出策略，系统会根据进程出现在队列上的位置选择执行的顺序；若为轮转策略，系统会为实时进程分配时间片， 当一个时间片消耗完毕，就会执行下一个相同优先级的进程，如此循环往复，直到同优先级的所有进程执行完毕。

普通进程的调度方式： 动态优先级策略
系统调度时，会关注进程近一段时间内的表现（主要是睡眠时间和执行时间），再根据公式计算动态优先级，并严格按照动态优先级的高低顺序执行进程。其中，动态优先级是以静态优先级为基准进行计算的。若进程为交互式进程（如：桌面程序、服务器等），由于睡眠时间较长，对应的动态优先级也应该较高，当输入到来时能很快地被执行；若进程为批处理进程（如：编译程序），会较长时间处于可执行状态，可适当较低动态优先级，让系统先执行比较紧急的进程。



**5.跨进程通信的方式，信号量怎么理解？**

可以理解为一个计数器



**6.操作系统层面，怎么实现异常中断？**





**7.用户态和内核态有什么区别？**

**1）内核态与用户态是操作系统的两种运行级别，当程序运行在3级特权级上时，就可以称之为运行在用户态。**因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；

**2）当程序运行在0级特权级上时，就可以称之为运行在内核态。**

**3）运行在用户态下的程序不能直接访问操作系统内核数据结构和程序。当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态。**

**4）这两种状态的主要差别是**：

- 处于用户态执行时，进程所能访问的内存空间和对象受到限制，其所处于占有的处理机是可被抢占的 ；
- 而处于核心态执行中的进程，则能访问所有的内存空间和对象，且所占有的处理机是不允许被抢占的。



三种情况会导致用户态到内核态的切换

* 系统调用

> 这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作

* 异常

> 当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

* 外围设备中断

> 当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，
>
> 如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。











### 计算机网络

**1.浏览器中输入域名（url）后发生了什么？**

[键入网址后，期间发生了什么？](https://mp.weixin.qq.com/s/I6BLwbIpfGEJnxjDcPXc1A)

* 解析url，通过DNS解析（DNS解析用的UDP协议）域名成ip地址
* 根据该 IP 地址和默认端口 80，建立TCP连接，3次握手
* 发送http请求
* 服务器处理请求
* 返回http响应
* 关闭TCP连接
* 浏览器解析渲染页面



**2.DNS解析流程**

通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。

DNS协议运行在UDP协议之上，使用端口号53。

1. 客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。
2. 本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 www.server.com 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。
3. 根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”
4. 本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com  的 IP 地址吗？”
5. 顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”。
6. 本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。
7. 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。
8. 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。



DNS 协议的可靠性的设计？



**3.TCP 的拥塞控制机制**

我们知道TCP通过一个定时器（timer）采样了RTT并计算RTO，但是，如果网络上的延时突然增加，那么，TCP对这个事做出的应对只有重传数据，然而重传会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这就导致了恶性循环，最终形成“网络风暴” —— TCP的拥塞控制机制就是用于应对这种情况。
首先需要了解一个概念，为了在发送端调节所要发送的数据量，定义了一个“拥塞窗口”（Congestion Window），在发送数据时，将拥塞窗口的大小与接收端ack的窗口大小做比较，取较小者作为发送数据量的上限。
拥塞控制主要是四个算法：
1.慢启动：意思是刚刚加入网络的连接，一点一点地提速，不要一上来就把路占满。
连接建好的开始先初始化cwnd = 1，表明可以传一个MSS大小的数据。
每当收到一个ACK，cwnd++; 呈线性上升
每当过了一个RTT，cwnd = cwnd*2; 呈指数让升
阈值ssthresh（slow start threshold），是一个上限，当cwnd >= ssthresh时，就会进入“拥塞避免算法”
2.拥塞避免：当拥塞窗口 cwnd 达到一个阈值时，窗口大小不再呈指数上升，而是以线性上升，避免增长过快导致网络拥塞。
每当收到一个ACK，cwnd = cwnd + 1/cwnd
每当过了一个RTT，cwnd = cwnd + 1
拥塞发生：当发生丢包进行数据包重传时，表示网络已经拥塞。分两种情况进行处理：
等到RTO超时，重传数据包
sshthresh = cwnd /2
cwnd 重置为 1
3.进入慢启动过程
在收到3个duplicate ACK时就开启重传，而不用等到RTO超时
sshthresh = cwnd = cwnd /2
进入快速恢复算法——Fast Recovery
4.快速恢复：至少收到了3个Duplicated Acks，说明网络也不那么糟糕，可以快速恢复。
cwnd = sshthresh + 3 * MSS （3的意思是确认有3个数据包被收到了）
重传Duplicated ACKs指定的数据包
如果再收到 duplicated Acks，那么cwnd = cwnd +1
如果收到了新的Ack，那么，cwnd = sshthresh ，然后就进入了拥塞避免的算法了。

**4.Http**

超文本传输协议，HTTP是缩写，它的全英文名是HyperText Transfer Protocol。

> **HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。**

**HTTP/1.1、HTTP/2、HTTP/3 演变**

HTTP/1.1 相比 HTTP/1.0 性能上的改进：

- 使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
- 支持 管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

但 HTTP/1.1 还是有性能瓶颈：

- 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 `Body` 的部分；
- 发送冗长的首部。每次互相发送相同的首部造成的浪费较多；
- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；
- 没有请求优先级控制；
- 请求只能从客户端开始，服务器只能被动响应。

HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。

那 HTTP/2 相比 HTTP/1.1 性能上的改进：

*1. 头部压缩*

HTTP/2 会**压缩头**（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你**消除重复的分**。

这就是所谓的 `HPACK` 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就**提高速度**了。

*2. 二进制格式*

HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了**二进制格式。**

头信息和数据体都是二进制，并且统称为帧（frame）：**头信息帧和数据帧**。

*3. 数据流*

HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。

每个请求或回应的所有数据包，称为一个数据流（`Stream`）。

每个数据流都标记着一个独一无二的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数

客户端还可以**指定数据流的优先级**。优先级高的请求，服务器就先响应该请求。

*4. 多路复用*

HTTP/2 是可以在**一个连接中并发多个请求或回应，而不用按照顺序一一对应**。

移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，**降低了延迟，大幅度提高了连接的利用率**。

*5. 服务器推送*

HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以**主动**向客户端发送消息。

> HTTP/2 有哪些缺陷？HTTP/3 做了哪些优化？

HTTP/2 主要的问题在于：多个 HTTP 请求在复用一个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。

所以一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的**所有的 HTTP 请求都必须等待这个丢了的包被重传回来**。

- HTTP/1.1 中的管道（ pipeline）传输中如果有一个请求阻塞了，那么队列后请求也统统被阻塞住了
- HTTP/2 多请求复用一个TCP连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求。

这都是基于 TCP 传输层的问题，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！**

![http演进.png](http://ww1.sinaimg.cn/large/0072fULUgy1grk3zxvsp7j60mg0anwjb02.jpg)











**5.HTTP 与 HTTPS 有哪些区别？**

1. HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
2. HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
3. HTTP 的端口号是 80，HTTPS 的端口号是 443。
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

[HTTP 与 HTTPS](https://mp.weixin.qq.com/s/amOya0M00LwpL5kCS96Y6w)



**6.HTTPS是怎么保证安全的**

*1. 混合加密*

HTTPS 采用的是**对称加密**和**非对称加密**结合的「混合加密」方式：

- 在通信建立前采用**非对称加密**的方式交换「会话秘钥」，后续就不再使用非对称加密。
- 在通信过程中全部使用**对称加密**的「会话秘钥」的方式加密明文数据。

采用「混合加密」的方式的原因：

- **对称加密**只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。
- **非对称加密**使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。

*2. 摘要算法*

**摘要算法**用来实现**完整性**，能够为数据生成独一无二的「指纹」，用于校验数据的完整性，解决了篡改的风险。

客户端在发送明文之前会通过摘要算法算出明文的「指纹」，发送的时候把「指纹 + 明文」一同
加密成密文后，发送给服务器，服务器解密后，用相同的摘要算法算出发送过来的明文，通过比较客户端携带的「指纹」和当前算出的「指纹」做比较，若「指纹」相同，说明数据是完整的。

*3. 数字证书*

客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。这就存在些问题，如何保证公钥不被篡改和信任度？

所以这里就需要借助第三方权威机构 `CA` （数字证书认证机构），将**服务器公钥放在数字证书**（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。



HTTPS 的出发点是解决HTTP明文传输时信息被篡改和监听的问题。

- 为了兼顾性能和安全性，使用了非对称加密+对称加密的方案。
- 为了保证公钥传输中不被篡改，又使用了非对称加密的数字签名功能，借助CA机构和系统根证书的机制保证了HTTPS证书的公信力。



[详解HTTPS加解密数字签名](https://mp.weixin.qq.com/s/21JaXwdfSjItj5SgOwhapg)



**7.对称加密和非对称加密的区别**

对称加密是指有一个密钥，用它可以对一段明文加密，加密之后也只能用这个密钥来解密得到明文。

非对称加密有两个密钥，一个是公钥，另一个是私钥。一般来说，公钥用来加密，这时密文只能用私钥才能解开。



**8.常见的加密算法有哪些？**

* AES（Advanced Encryption Standard）：高级加密标准，对称算法，是下一代的加密算法标准，速度快，安全级别高，在21世纪AES 标准的一个实现是 Rijndael 算法；

* DES（Data Encryption Standard）：对称算法，数据加密标准，速度较快，适用于加密大量数据的场合；

* 3DES（Triple DES）：是基于DES的对称算法，对一块数据用三个不同的密钥进行三次加密，强度更高；

* RC2和RC4：对称算法，用变长密钥对大量数据进行加密，比 DES 快；

* IDEA（International Data Encryption Algorithm）国际数据加密算法，使用 128 位密钥提供非常强的安全性；

* RSA：由 RSA 公司发明，是一个支持变长密钥的公共密钥算法，需要加密的文件块的长度也是可变的，非对称算法；

* DSA（Digital Signature Algorithm）：数字签名算法，是一种标准的 DSS（数字签名标准），严格来说不算加密算法；

* MD5：严格来说不算加密算法，只能说是摘要算法。



**9.SYN泛洪攻击**

SYN泛洪攻击利用TCP三次握手协议的缺陷，向目标主机发送大量的伪造源地址的SYN连接请求，使得被攻击方资源耗尽，从而不能够为正常用户提供服务。

在TCP协议中被称为三次握手（Three-way Handshake）的连接过程中，如果一个用户向服务器发送了SYN报文，服务器又发出 SYN+ACK 应答报文后**未收到客户端的 ACK 报文**，这种情况下服务器端会再次发送SYN+ACK给客户端，并等待一段时间后丢弃这个未完成的连接，这段时间的长度称为SYN Timeout，一般来说这个时间是分钟的数量级。

SYN 泛洪攻击所做的就是利用这个SYN Timeout和TCP/IP协议族中的另一个漏洞: 报文传输过程中对报文的源 IP 地址完全信任进行攻击。SYN 泛洪攻击通过发送大量的伪造 TCP 链接报文而造成大量的 TCP 半连接,服务器端将为了维护这样一个庞大的半连接列表而消耗非常多的资源。这样服务器端将忙于处理攻击者伪造的TCP连接请求而无法处理正常连接请求,甚至会导致堆栈的溢出崩溃
造成SYN洪泛攻击最主要的原因是TCP/IP协议的脆弱性。TCP/IP是一个开放的协议平台，它将越来越多的网络连接在一起，它基于的对象是可信用户群，所以缺少一些必要的安全机制，带来很大的安全威胁。例如常见的IP欺骗、TCP连接的建立、ICMP数据包的发送都存在巨大的安全隐患，给SYN洪泛攻击带来可乘之机。

SYN泛洪防御技术：

- **缩短SYN timeout时间**

* **设置SYN cookie**

* **设置SYN可疑队列**
* **使用防火墙**

[TCP SYN洪泛攻击的原理及防御方法](https://blog.csdn.net/jiangzhengdong/article/details/8119223)

