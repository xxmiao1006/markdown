## MySQL索引原理解析

​		索引的本质

​		MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。



### 一. B-树、B+树简介 

​		目前大部分数据库系统及文件系统都采用B-Tree或其变种B+Tree作为索引结构。

​		B-树，也称为B树，是一种平衡的多叉树（可以对比一下平衡二叉查找树），它比较适用于对外查找

- 阶数：一个节点最多有多少个孩子节点。（一般用字母m表示）

- 关键字：节点上的数值就是关键字

- 度：一个节点拥有的子节点的数量。

  一颗m阶的B-树，有以下特征：

- 根结点至少有两个子女；

- 每个非根节点所包含的关键字个数 j 满足：⌈m/2⌉ - 1 <= j <= m - 1.(⌈⌉表示向上取整)

- 有k个关键字(关键字按递增次序排列)的非叶结点恰好有k+1个孩子。

- 所有的叶子结点都位于同一层。

  ![B-tree.png](http://ww1.sinaimg.cn/large/0072fULUly1gosg9io5nij30f305b74c.jpg)

  

  B+树是B-树的变体，也是一颗多路搜索树。一棵m阶的B+树主要有这些特点：

- 每个结点至多有m个子女;

- 非根节点关键值个数范围：⌈m/2⌉ - 1 <= k <= m-1

- 相邻叶子节点是通过指针连起来的，并且是关键字大小排序的。

  一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。

  

  ![B+tree.png](http://ww1.sinaimg.cn/large/0072fULUly1gosg8d5ybyj30f305bmx8.jpg)

  

  

  **B+树和B-树的主要区别**如下：

- B-树内部节点是保存数据的;而B+树内部节点是不保存数据的，只作索引作用，它的叶子节点才保存数据。

- B+树相邻的叶子节点之间是通过链表指针连起来的，B-树却不是。

- 查找过程中，B-树在找到具体的数值以后就结束，而B+树则需要通过索引找到叶子结点中的数据才结束

- B-树中任何一个关键字出现且只出现在一个结点中，而B+树可以出现多次。



### 二. 内存磁盘读取原理

​		上文说过，红黑树等数据结构也可以用来实现索引，但是文件系统及数据库系统普遍采用B-/+Tree作为索引结构，一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。下面先介绍内存和磁盘存取原理，然后再结合这些原理分析B-/+Tree作为索引的效率。

#### 1. 主存存取原理

​		目前计算机使用的主存基本都是随机读写存储器（RAM），现代RAM的结构和存取原理比较复杂，这里抛却具体差别，抽象出一个十分简单的存取模型来说明RAM的工作原理。

![主存存取原理.png](http://ww1.sinaimg.cn/large/0072fULUly1gosgjyhyucj30am06dwei.jpg)



​		从抽象角度看，主存是一系列的存储单元组成的矩阵，每个存储单元存储固定大小的数据。每个存储单元有唯一的地址，现代主存的编址规则比较复杂，这里将其简化成一个二维地址：通过一个行地址和一个列地址可以唯一定位到一个存储单元。图5展示了一个4 x 4的主存模型。

主存的存取过程如下：

​		当系统需要读取主存时，则将地址信号放到地址总线上传给主存，主存读到地址信号后，解析信号并定位到指定存储单元，然后将此存储单元数据放到数据总线上，供其它部件读取。

​		写主存的过程类似，系统将要写入单元地址和数据分别放在地址总线和数据总线上，主存读取两个总线的内容，做相应的写操作。

​		这里可以看出，主存存取的时间仅与存取次数呈线性关系，因为不存在机械操作，两次存取的数据的“距离”不会对时间有任何影响，例如，先取A0再取A1和先取A0再取D3的时间消耗是一样的。



#### 2. 磁盘存取原理

​		上文说过，索引一般以文件形式存储在磁盘上，索引检索需要磁盘I/O操作。与主存不同，磁盘I/O存在机械运动耗费，因此磁盘I/O的时间消耗是巨大的。

![磁盘存取原理.png](http://ww1.sinaimg.cn/large/0072fULUly1gosgnb9fpsj30co06qq2u.jpg)



​		一个磁盘由大小相同且同轴的圆形盘片组成，磁盘可以转动（各个磁盘必须同步转动）。在磁盘的一侧有磁头支架，磁头支架固定了一组磁头，每个磁头负责存取一个磁盘的内容。磁头不能转动，但是可以沿磁盘半径方向运动（实际是斜切向运动），每个磁头同一时刻也必须是同轴的，即从正上方向下看，所有磁头任何时候都是重叠的（不过目前已经有多磁头独立技术，可不受此限制）。

![磁盘结构.png](http://ww1.sinaimg.cn/large/0072fULUly1gosgoxc0nvj30d1087dfx.jpg)



​		盘片被划分成一系列同心环，圆心是盘片中心，每个同心环叫做一个磁道，所有半径相同的磁道组成一个柱面。磁道被沿半径线划分成一个个小的段，每个段叫做一个扇区，每个扇区是磁盘的最小存储单元。为了简单起见，我们下面假设磁盘只有一个盘片和一个磁头。

​		当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点，磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，然后磁盘旋转将目标扇区旋转到磁头下，这个过程耗费的时间叫做旋转时间。

#### 3. 局部性原理与磁盘预读

​		由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：

​		当一个数据被用到时，其附近的数据也通常会马上被使用。

​		程序运行期间所需要的数据通常比较集中。

​		由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。

​		预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。

#### 4. B-/+Tree索引的性能分析

​		上文说过一般使用磁盘I/O次数评价索引结构的优劣。先从B-Tree分析，根据B-Tree的定义，可知检索一次最多需要访问h个节点。**数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入**。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：

​		每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，**就实现了一个node只需一次I/O**。

​		B-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为O(h)=O(logdN)O(h)=O(logdN)。一般实际应用中，**出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3）**。

综上所述，用B-Tree作为索引结构效率是非常高的。

而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。

上文还说过，B+Tree更适合外存索引，原因和内节点出度d有关。从上面分析可以看到，d越大索引的性能越好，而出度的上限取决于节点内key和data的大小：

dmax=floor(pagesize/(keysize+datasize+pointsize))dmax=floor(pagesize/(keysize+datasize+pointsize))

floor表示向下取整。由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。



### 三. MySQL的索引实现

​		在MySQL中，索引属于存储引擎级别的实现，不同存储引擎对索引的实现方式是不同的，下面主要对MySQL两个主要的存储引擎MyISAM和InnoDB的索引进行讨论。

#### 1. MyISAM的实现

​		MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM索引的原理图：

![MyISAM索引原理图.png](http://ww1.sinaimg.cn/large/0072fULUly1goshbh4zkzj30p90e2t97.jpg)



​		这里设表一共有三列，假设我们以Col1为主键，则上图是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示：

![MyISAM辅助索引原理图.png](http://ww1.sinaimg.cn/large/0072fULUly1goshcy6bm4j30pz0e2wez.jpg)



同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。

MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。我们从数据库的文件里也可以看到，存储引擎为MyISAM的数据库表共有3个文件，分别是数据文件`.MYD`、索引文件 `.MYI`、表结构文件 `.frm`。索引中叶子节点存的是数据的内存地址，所以也叫做**非聚集索引**



#### 2. InnoDB的实现

​		InnoDB的索引虽然也是用B+tree作为索引结构，但具体的实现却与MyISAM的实现截然不同

​		第一个重大区别就是InnoDB的数据文件本身就是索引文件，所以又被叫做**聚集索引**。从上文知道，MyISAM的数据文件和索引文件是分离的，索引文件仅仅保存数据地址，而在InnoDB中，表的数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶子节点保存了完整的数据记录，这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。

![InnoDB索引原理图.png](http://ww1.sinaimg.cn/large/0072fULUly1goshybk94fj30ie07ct8t.jpg)



​		上图是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，**所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形**。

​		第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。例如，下图为定义在Col3上的一个辅助索引：

![InnoDB辅助索引原理图.png](http://ww1.sinaimg.cn/large/0072fULUly1gosi0vzi9vj30ie07aglp.jpg)

​		这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。

​		了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么**不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。**



### 四. 最左索引匹配原则

高效使用索引的首要条件是知道什么样的查询会使用到索引，这个问题和B+Tree中的“最左前缀原理”有关，下面通过例子说明最左前缀原理。

这里先说一下联合索引的概念。在上文中，我们都是假设索引只引用了单个的列，实际上，MySQL中的索引可以以一定顺序引用多个列，这种索引叫做联合索引，一般的，一个联合索引是一个有序元组<a1, a2, …, an>，其中各个元素均为数据表的一列，实际上要严格定义索引需要用到关系代数，但是这里我不想讨论太多关系代数的话题，因为那样会显得很枯燥，所以这里就不再做严格定义。另外，单列索引可以看成联合索引元素数为1的特例。

以employees.titles表为例，下面先查看其上都有哪些索引：

```sql
SHOW INDEX FROM employees.titles;
+--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+
| Table  | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Null | Index_type |
+--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+
| titles |          0 | PRIMARY  |            1 | emp_no      | A         |        NULL |      | BTREE      |
| titles |          0 | PRIMARY  |            2 | title       | A         |        NULL |      | BTREE      |
| titles |          0 | PRIMARY  |            3 | from_date   | A         |      443308 |      | BTREE      |
| titles |          1 | emp_no   |            1 | emp_no      | A         |      443308 |      | BTREE      |
+--------+------------+----------+--------------+-------------+-----------+-------------+------+------------+
```

从结果中可以到titles表的主索引为<emp_no, title, from_date>，还有一个辅助索引<emp_no>。为了避免多个索引使事情变复杂（MySQL的SQL优化器在多索引时行为比较复杂），这里我们将辅助索引drop掉：

```sql
ALTER TABLE employees.titles DROP INDEX emp_no;
```

这样就可以专心分析索引PRIMARY的行为了。

#### 情况一：全列匹配

```sql
EXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001' AND title='Senior Engineer' AND from_date='1986-06-26';
+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+
| id | select_type | table  | type  | possible_keys | key     | key_len | ref               | rows | Extra |
+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+
|  1 | SIMPLE      | titles | const | PRIMARY       | PRIMARY | 59      | const,const,const |    1 |       |
+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+
```

​		很明显，当按照索引中所有列进行精确匹配（这里精确匹配指“=”或“IN”匹配）时，索引可以被用到。这里有一点需要注意，理论上索引对顺序是敏感的，但是由于MySQL的查询优化器会自动调整where子句的条件顺序以使用适合的索引，例如我们将where中的条件顺序颠倒：

```sql
EXPLAIN SELECT * FROM employees.titles WHERE from_date='1986-06-26' AND emp_no='10001' AND title='Senior Engineer';
+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+
| id | select_type | table  | type  | possible_keys | key     | key_len | ref               | rows | Extra |
+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+
|  1 | SIMPLE      | titles | const | PRIMARY       | PRIMARY | 59      | const,const,const |    1 |       |
+----+-------------+--------+-------+---------------+---------+---------+-------------------+------+-------+
```

效果是一样的。

#### 情况二：最左前缀匹配

```sql
EXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001';
+----+-------------+--------+------+---------------+---------+---------+-------+------+-------+
| id | select_type | table  | type | possible_keys | key     | key_len | ref   | rows | Extra |
+----+-------------+--------+------+---------------+---------+---------+-------+------+-------+
|  1 | SIMPLE      | titles | ref  | PRIMARY       | PRIMARY | 4       | const |    1 |       |
+----+-------------+--------+------+---------------+---------+---------+-------+------+-------+
```

​		当查询条件精确匹配索引的左边连续一个或几个列时，如<emp_no>或<emp_no, title>，所以可以被用到，但是只能用到一部分，即条件所组成的最左前缀。上面的查询从分析结果看用到了PRIMARY索引，但是key_len为4，说明只用到了索引的第一列前缀。

#### 情况三：查询条件用到了索引中列的精确匹配，但是中间某个条件未提供

```sql
EXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001' AND from_date='1986-06-26';
+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+
| id | select_type | table  | type | possible_keys | key     | key_len | ref   | rows | Extra       |
+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+
|  1 | SIMPLE      | titles | ref  | PRIMARY       | PRIMARY | 4       | const |    1 | Using where |
+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+
```

​		此时索引使用情况和情况二相同，因为title未提供，所以查询只用到了索引的第一列，而后面的from_date虽然也在索引中，但是由于title不存在而无法和左前缀连接，因此需要对结果进行扫描过滤from_date（这里由于emp_no唯一，所以不存在扫描）。如果想让from_date也使用索引而不是where过滤，可以增加一个辅助索引<emp_no, from_date>，此时上面的查询会使用这个索引。除此之外，还可以使用一种称之为“隔离列”的优化方法，将emp_no与from_date之间的“坑”填上。

首先我们看下title一共有几种不同的值：

```sql
SELECT DISTINCT(title) FROM employees.titles;
+--------------------+
| title              |
+--------------------+
| Senior Engineer    |
| Staff              |
| Engineer           |
| Senior Staff       |
| Assistant Engineer |
| Technique Leader   |
| Manager            |
+--------------------+
```

​		只有7种。在这种成为“坑”的列值比较少的情况下，可以考虑用“IN”来填补这个“坑”从而形成最左前缀：

```sql
EXPLAIN SELECT * FROM employees.titles
WHERE emp_no='10001'
AND title IN ('Senior Engineer', 'Staff', 'Engineer', 'Senior Staff', 'Assistant Engineer', 'Technique Leader', 'Manager')
AND from_date='1986-06-26';
+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+
| id | select_type | table  | type  | possible_keys | key     | key_len | ref  | rows | Extra       |
+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+
|  1 | SIMPLE      | titles | range | PRIMARY       | PRIMARY | 59      | NULL |    7 | Using where |
+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+
```

​		这次key_len为59，说明索引被用全了，但是从type和rows看出IN实际上执行了一个range查询，这里检查了7个key。看下两种查询的性能比较：

```sql
SHOW PROFILES;
+----------+------------+-------------------------------------------------------------------------------+
| Query_ID | Duration   | Query                                                                         |
+----------+------------+-------------------------------------------------------------------------------+
|       10 | 0.00058000 | SELECT * FROM employees.titles WHERE emp_no='10001' AND from_date='1986-06-26'|
|       11 | 0.00052500 | SELECT * FROM employees.titles WHERE emp_no='10001' AND title IN ...          |
+----------+------------+-------------------------------------------------------------------------------+
```

​		“填坑”后性能提升了一点。如果经过emp_no筛选后余下很多数据，则后者性能优势会更加明显。当然，如果title的值很多，用填坑就不合适了，必须建立辅助索引。

#### 情况四：查询条件没有指定索引第一列

```sql
EXPLAIN SELECT * FROM employees.titles WHERE from_date='1986-06-26';
+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+
| id | select_type | table  | type | possible_keys | key  | key_len | ref  | rows   | Extra       |
+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+
|  1 | SIMPLE      | titles | ALL  | NULL          | NULL | NULL    | NULL | 443308 | Using where |
+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+
```

​		由于不是最左前缀，索引这样的查询显然用不到索引。

#### 情况五：匹配某列的前缀字符串

```sql
EXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001' AND title LIKE 'Senior%';
+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+
| id | select_type | table  | type  | possible_keys | key     | key_len | ref  | rows | Extra       |
+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+
|  1 | SIMPLE      | titles | range | PRIMARY       | PRIMARY | 56      | NULL |    1 | Using where |
+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+
```

​		此时可以用到索引，~~但是如果通配符不是只出现在末尾，则无法使用索引。~~（原文表述有误，如果通配符%不出现在开头，则可以用到索引，但根据具体情况不同可能只会用其中一个前缀）

#### 情况六：范围查询

```sql
EXPLAIN SELECT * FROM employees.titles WHERE emp_no < '10010' and title='Senior Engineer';
+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+
| id | select_type | table  | type  | possible_keys | key     | key_len | ref  | rows | Extra       |
+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+
|  1 | SIMPLE      | titles | range | PRIMARY       | PRIMARY | 4       | NULL |   16 | Using where |
+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+
```

​		范围列可以用到索引（必须是最左前缀），但是范围列后面的列无法用到索引。同时，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引。

```sql
EXPLAIN SELECT * FROM employees.titles
WHERE emp_no < '10010'
AND title='Senior Engineer'
AND from_date BETWEEN '1986-01-01' AND '1986-12-31';
+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+
| id | select_type | table  | type  | possible_keys | key     | key_len | ref  | rows | Extra       |
+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+
|  1 | SIMPLE      | titles | range | PRIMARY       | PRIMARY | 4       | NULL |   16 | Using where |
+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+
```

​		可以看到索引对第二个范围索引无能为力。这里特别要说明MySQL一个有意思的地方，那就是仅用explain可能无法区分范围索引和多值匹配，因为在type中这两者都显示为range。同时，用了“between”并不意味着就是范围查询，例如下面的查询：

```sql
EXPLAIN SELECT * FROM employees.titles
WHERE emp_no BETWEEN '10001' AND '10010'
AND title='Senior Engineer'
AND from_date BETWEEN '1986-01-01' AND '1986-12-31';
+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+
| id | select_type | table  | type  | possible_keys | key     | key_len | ref  | rows | Extra       |
+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+
|  1 | SIMPLE      | titles | range | PRIMARY       | PRIMARY | 59      | NULL |   16 | Using where |
+----+-------------+--------+-------+---------------+---------+---------+------+------+-------------+
```

​		看起来是用了两个范围查询，但作用于emp_no上的“BETWEEN”实际上相当于“IN”，也就是说emp_no实际是多值精确匹配。可以看到这个查询用到了索引全部三个列。因此在MySQL中要谨慎地区分多值匹配和范围匹配，否则会对MySQL的行为产生困惑。

#### 情况七：查询条件中含有函数或表达式

​		很不幸，如果查询条件中含有函数或表达式，则MySQL不会为这列使用索引（虽然某些在数学意义上可以使用）。例如：

```sql
EXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001' AND left(title, 6)='Senior';
+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+
| id | select_type | table  | type | possible_keys | key     | key_len | ref   | rows | Extra       |
+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+
|  1 | SIMPLE      | titles | ref  | PRIMARY       | PRIMARY | 4       | const |    1 | Using where |
+----+-------------+--------+------+---------------+---------+---------+-------+------+-------------+
```

​		虽然这个查询和情况五中功能相同，但是由于使用了函数left，则无法为title列应用索引，而情况五中用LIKE则可以。再如：

```sql
EXPLAIN SELECT * FROM employees.titles WHERE emp_no - 1='10000';
+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+
| id | select_type | table  | type | possible_keys | key  | key_len | ref  | rows   | Extra       |
+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+
|  1 | SIMPLE      | titles | ALL  | NULL          | NULL | NULL    | NULL | 443308 | Using where |
+----+-------------+--------+------+---------------+------+---------+------+--------+-------------+
```

​		显然这个查询等价于查询emp_no为10001的函数，但是由于查询条件是一个表达式，MySQL无法为其使用索引。看来MySQL还没有智能到自动优化常量表达式的程度，因此在写查询语句时尽量避免表达式出现在查询中，而是先手工私下代数运算，转换为无表达式的查询语句。

#### 索引选择性与前缀索引

​		既然索引可以加快查询速度，那么是不是只要是查询语句需要，就建上索引？答案是否定的。因为索引虽然加快了查询速度，但索引也是有代价的：索引文件本身要消耗存储空间，同时索引会加重插入、删除和修改记录时的负担，另外，MySQL在运行时也要消耗资源维护索引，因此索引并不是越多越好。一般两种情况下不建议建索引。

​		第一种情况是表记录比较少，例如一两千条甚至只有几百条记录的表，没必要建索引，让查询做全表扫描就好了。至于多少条记录才算多，这个个人有个人的看法，我个人的经验是以2000作为分界线，记录数不超过 2000可以考虑不建索引，超过2000条可以酌情考虑索引。

​		另一种不建议建索引的情况是索引的选择性较低。所谓索引的选择性（Selectivity），是指不重复的索引值（也叫基数，Cardinality）与表记录数（#T）的比值：

Index Selectivity = Cardinality / #T

​		显然选择性的取值范围为(0, 1]，选择性越高的索引价值越大，这是由B+Tree的性质决定的。例如，上文用到的employees.titles表，如果title字段经常被单独查询，是否需要建索引，我们看一下它的选择性：

```sql
SELECT count(DISTINCT(title))/count(*) AS Selectivity FROM employees.titles;
+-------------+
| Selectivity |
+-------------+
|      0.0000 |
+-------------+
```

​		title的选择性不足0.0001（精确值为0.00001579），所以实在没有什么必要为其单独建索引。

​		有一种与索引选择性有关的索引优化策略叫做前缀索引，就是用列的前缀代替整个列作为索引key，当前缀长度合适时，可以做到既使得前缀索引的选择性接近全列索引，同时因为索引key变短而减少了索引文件的大小和维护开销。下面以employees.employees表为例介绍前缀索引的选择和使用。

​		从图可以看到employees表只有一个索引<emp_no>，那么如果我们想按名字搜索一个人，就只能全表扫描了：

```sql
EXPLAIN SELECT * FROM employees.employees WHERE first_name='Eric' AND last_name='Anido';
+----+-------------+-----------+------+---------------+------+---------+------+--------+-------------+
| id | select_type | table     | type | possible_keys | key  | key_len | ref  | rows   | Extra       |
+----+-------------+-----------+------+---------------+------+---------+------+--------+-------------+
|  1 | SIMPLE      | employees | ALL  | NULL          | NULL | NULL    | NULL | 300024 | Using where |
+----+-------------+-----------+------+---------------+------+---------+------+--------+-------------+
```

​		如果频繁按名字搜索员工，这样显然效率很低，因此我们可以考虑建索引。有两种选择，建<first_name>或<first_name, last_name>，看下两个索引的选择性：

```sql
SELECT count(DISTINCT(first_name))/count(*) AS Selectivity FROM employees.employees;
+-------------+
| Selectivity |
+-------------+
|      0.0042 |
+-------------+
SELECT count(DISTINCT(concat(first_name, last_name)))/count(*) AS Selectivity FROM employees.employees;
+-------------+
| Selectivity |
+-------------+
|      0.9313 |
+-------------+
```

​		<first_name>显然选择性太低，<first_name, last_name>选择性很好，但是first_name和last_name加起来长度为30，有没有兼顾长度和选择性的办法？可以考虑用first_name和last_name的前几个字符建立索引，例如<first_name, left(last_name, 3)>，看看其选择性：

```sql
SELECT count(DISTINCT(concat(first_name, left(last_name, 3))))/count(*) AS Selectivity FROM employees.employees;
+-------------+
| Selectivity |
+-------------+
|      0.7879 |
+-------------+
```

​		选择性还不错，但离0.9313还是有点距离，那么把last_name前缀加到4：

```sql
SELECT count(DISTINCT(concat(first_name, left(last_name, 4))))/count(*) AS Selectivity FROM employees.employees;
+-------------+
| Selectivity |
+-------------+
|      0.9007 |
+-------------+
```

​		这时选择性已经很理想了，而这个索引的长度只有18，比<first_name, last_name>短了接近一半，我们把这个前缀索引建上：

```sql
ALTER TABLE employees.employees
ADD INDEX `first_name_last_name4` (first_name, last_name(4));
```

​		此时再执行一遍按名字查询，比较分析一下与建索引前的结果：

```sql
SHOW PROFILES;
+----------+------------+---------------------------------------------------------------------------------+
| Query_ID | Duration   | Query                                                                           |
+----------+------------+---------------------------------------------------------------------------------+
|       87 | 0.11941700 | SELECT * FROM employees.employees WHERE first_name='Eric' AND last_name='Anido' |
|       90 | 0.00092400 | SELECT * FROM employees.employees WHERE first_name='Eric' AND last_name='Anido' |
+----------+------------+---------------------------------------------------------------------------------+
```

​		性能的提升是显著的，查询速度提高了120多倍。

​		前缀索引兼顾索引大小和查询速度，但是其缺点是不能用于ORDER BY和GROUP BY操作，也不能用于Covering index（即当索引本身包含查询所需全部数据时，不再访问数据文件本身）。

#### InnoDB的主键选择与插入优化

​		在使用InnoDB存储引擎时，如果没有特别的需要，请**永远使用一个与业务无关的自增字段作为主键**。

​		经常看到有帖子或博客讨论主键选择问题，有人建议使用业务无关的自增主键，有人觉得没有必要，完全可以使用如学号或身份证号这种唯一字段作为主键。不论支持哪种论点，大多数论据都是业务层面的。如果从数据库索引优化角度看，使用InnoDB引擎而不使用自增主键绝对是一个糟糕的主意。

​		上文讨论过InnoDB的索引实现，InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）。

​		如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。如下图所示：

![InnoDB索引原理增加页.png](http://ww1.sinaimg.cn/large/0072fULUly1gosn7f2fhgj30hb06qjrc.jpg)



​		**这样就会形成一个紧凑的索引结构，近似顺序填满**。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。

​		如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置：



![InnoDB索引原理插入.png](http://ww1.sinaimg.cn/large/0072fULUly1gosn9vzc8bj30bb070wee.jpg)



​		**此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面**。

因此，只要可以，**请尽量在InnoDB上采用自增字段做主键**



### 五. 相关问题及答案总结

#### 1.**为什么索引结构默认使用B+树，而不是B-Tree，Hash哈希，二叉树，红黑树？**

- Hash哈希，只适合等值查询，不适合范围查询。
- 一般二叉树，可能会特殊化为一个链表，相当于全表扫描。
- 红黑树，是一种特化的平衡二叉树，MySQL 数据量很大的时候，索引的体积也会很大，内存放不下的而从磁盘读取，树的层次太高的话，读取磁盘的次数就多了。
- B-Tree，叶子节点和非叶子节点都保存数据，相同的数据量，B+树更矮壮，也是就说，相同的数据量，B+树数据结构，查询磁盘的次数会更少。



#### 2.为什么innodb推荐使用自增id做主键

* 索引底层实现默认是使用B+Tree  一般mysql会设置一个节点的大小为一页的大小（内存与磁盘交换的单位）保证一次io能读取完一个节点，自增id相较于uuid或者雪花id更小，degree更大，树更矮胖

* 查找数据需要比较主键大小，很明显int类型的数比较大小比uuid等数据比较大小的速度更快，字符串比较是比较ASCII码

* 使用uuid或者无序随机的主键在插入时很容易造成索引的重构即B+tree的重构，随机插入很容易破坏b+树的特性，造成节点的分裂合并等。甚至有的目标已经从内存中清楚，又得从磁盘中读回来，又增加了io次数和额外的开销，同时频繁的移动分页造成了大量的碎片，得不到紧凑的索引结构，效率极其底下，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。而使用自增的id在节点大小固定为页大小的情况下，可以一直往后添加，一个节点满了开另一个节点，索引结构十分紧凑，基本无需进行重构，极大的增加了插入的效率。

* 还有一个是辅助索引到叶子节点里存储的是主键，如果主键过大也会令辅助索引变大。



#### 3.InnoDB一棵B+树可以存放多少行数据？

这个问题的简单回答是：约2千万行。

- 在计算机中，磁盘存储数据最小单元是扇区，一个扇区的大小是512字节。
- 文件系统中，最小单位是块，一个块大小就是4k；
- InnoDB存储引擎最小储存单元是页，一页大小就是16k。

> show VARIABLES like 'innodb_page_size' / 16384

因为B+树叶子存的是数据，内部节点存的是键值+指针。索引组织表通过非叶子节点的二分查找法以及指针确定数据在哪个页中，进而再去数据页中找到需要的数据；

假设B+树的高度为2的话，即有一个根结点和若干个叶子结点。这棵B+树的存放总记录数为=根结点指针数*单个叶子节点记录行数。

- 如果一行记录的数据大小为1k，那么单个叶子节点可以存的记录数 =16k/1k =16.

- 非叶子节点内存放多少指针呢？我们假设主键ID为bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节，所以就是8+6=14字节，16k/14B =16*1024B/14B = 1170

因此，一棵高度为2的B+树，能存放1170 * 16=18720条这样的数据记录。同理一棵高度为3的B+树，能存放1170 *1170 *16 =21902400，也就是说，可以存放两千万左右的记录。B+树高度一般为1-3层，已经满足千万级别的数据存储。



#### 4.为什么不推荐使用select 

* 可能回查询到不必要的列，包括一些不需要的大字段，增加时间传输和网络开销
* 如果使用mybatis,增减字段容易与 resultMap 配置不一致
* **失去MySQL优化器“覆盖索引”策略优化的可能性**



####   5.存储单元最小的页细节

- MySQL 一页默认16 KB，所以不是按数量的，是按总的记录数所占的空间。
- **页内记录是单向链表连接，页之间是双向链表连接**。
- 当一页数据存满了之后需要进行页分裂，也就是拆分下记录变成两个页。
- 页分裂操作也可能导致多个页都满了，比如你往一个页中间插入数据，挤出一条数据到下一页，然后下一页也满了，发生级联，影响性能，所以建议主键有序，这样不会往中间的页插入数据。
- **MySQL页内默认会有一条最大记录和一条最小记录不存储数据，就是这样设计的，和链表dummy节点类似**。
- 一页除了存储数据还有一些元数据，比如FileHeader、PageHeader等等
- 一条记录也有很多细节。



####   6.**MySQL的回表**

​		innodb主键索引为聚簇索引，叶子节点存储了完整的记录信息，而其他辅助索引（二级索引）叶子节点存储的指针，所以通过辅助索引查找数据只能查到id和索引列，如果还需要查找其他没有的字段需要通过主键回到主键索引再查询一次，这称之为回表操作（非常慢，需要扫描两遍索引树）。可以通过使用覆盖索引来优化辅助索引的回表操作，意思就是查询的字段通过辅助索引树就可以直接查出来，不需要通过回表操作查询其他字段的信息。

​		补充：如果无法使用覆盖索引优化回表操作，还有什么办法可以优化回表?

​					ICP：索引下推，通过索引下推来减少回表的次数

​					MRR：回表操作时通过id回表，但是id不一定是有序的，可能产生随机读，可以先将id排序，在回表查询，一般我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读



#### 7.MyISAM存储引擎键的长度

MyISAM存储引擎键的长度综合不能超过1000字节 InnoDB单列索引长度不能超过767bytes,联合索引还有一个限制是3072





#### 8.执行流程update

1.首先客户端通过tcp/ip发送一条sql语句到server层的SQL interface
2.SQL interface接到该请求后，先对该条语句进行解析，验证权限是否匹配
3.验证通过以后，分析器会对该语句分析,是否语法有错误等
4.接下来是优化器器生成相应的执行计划，选择最优的执行计划
5.之后会是执行器根据执行计划执行这条语句。在这一步会去open table,如果该table上有MDL，则等待。
如果没有，则加在该表上加短暂的MDL(S)
(如果opend_table太大,表明open_table_cache太小。需要不停的去打开frm文件)
6.进入到引擎层，首先会去innodb_buffer_pool里的data dictionary(元数据信息)得到表信息
7.通过元数据信息,去lock info里查出是否会有相关的锁信息，并把这条update语句需要的
锁信息写入到lock info里(锁这里还有待补充)
8.然后涉及到的老数据通过快照的方式存储到innodb_buffer_pool里的undo page里,并且记录undo log修改的redo
(如果data page里有就直接载入到undo page里，如果没有，则需要去磁盘里取出相应page的数据，载入到undo page里)
9.在innodb_buffer_pool的data page做update操作。并把操作的物理数据页修改记录到redo log buffer里
由于update这个事务会涉及到多个页面的修改，所以redo log buffer里会记录多条页面的修改信息。
因为group commit的原因，这次事务所产生的redo log buffer可能会跟随其它事务一同flush并且sync到磁盘上
10.同时修改的信息，会按照event的格式,记录到binlog_cache中。(这里注意binlog_cache_size是transaction级别的,不是session级别的参数,
一旦commit之后，dump线程会从binlog_cache里把event主动发送给slave的I/O线程)
11.之后把这条sql,需要在二级索引上做的修改，写入到change buffer page，等到下次有其他sql需要读取该二级索引时，再去与二级索引做merge
(随机I/O变为顺序I/O,但是由于现在的磁盘都是SSD,所以对于寻址来说,随机I/O和顺序I/O差距不大)
12.此时update语句已经完成，需要commit或者rollback。这里讨论commit的情况，并且双1
13.commit操作，由于存储引擎层与server层之间采用的是内部XA(保证两个事务的一致性,这里主要保证redo log和binlog的原子性),
所以提交分为prepare阶段与commit阶段
14.prepare阶段,将事务的xid写入，将binlog_cache里的进行flush以及sync操作(大事务的话这步非常耗时)
15.commit阶段，由于之前该事务产生的redo log已经sync到磁盘了。所以这步只是在redo log里标记commit
16.当binlog和redo log都已经落盘以后，如果触发了刷新脏页的操作，先把该脏页复制到doublewrite buffer里，把doublewrite buffer里的刷新到共享表空间，然后才是通过page cleaner线程把脏页写入到磁盘中
老师，你看我的步骤中有什么问题嘛？我感觉第6步那里有点问题,因为第5步已经去open table了，第6步还有没有必要去buffer里查找元数据呢?这元数据是表示的系统的元数据嘛,还是所有表的？谢谢老师指正





#### 9.索引下推(ICP Index Condition Pushdown)

索引下推把查询未用到的索引，传输给engine层，可以过滤掉部分数据，减少回表的操作（说明用在二级索引，主键索引中不存在ICP）。[MySQL ICP（Index Condition Pushdown）特性](https://www.cnblogs.com/Terry-Wu/p/9273177.html)

```sql
set optimizer_switch='index_condition_pushdown=on/off';
```

ICP的使用限制

1. 当sql需要全表访问时，ICP的优化策略可用于range, ref, eq_ref, ref_or_null类型的访问数据方法 。

2. 支持InnoDB和MyISAM表。

3. ICP只能用于二级索引，不能用于主索引。

4. 并非全部where条件都可以用ICP筛选，如果where条件的字段不在索引列中，还是要读取整表的记录到server端做where过滤。

5. ICP的加速效果取决于在存储引擎内通过ICP筛选掉的数据的比例。

6. MySQL 5.6版本的不支持分表的ICP功能，5.7版本的开始支持。

7. 当sql使用覆盖索引时，不支持ICP优化方法。

```sql
CREATE TABLE `tuser` (
  `id` int(11) NOT NULL,
  `id_card` varchar(32) DEFAULT NULL,
  `name` varchar(32) DEFAULT NULL,
  `age` int(11) DEFAULT NULL,
  `ismale` tinyint(1) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `id_card` (`id_card`),
  KEY `name_age` (`name`,`age`)
) ENGINE=InnoDB

--Using index condition
--根据最左匹配原则，用到了联合索引中的name字段，age字段没有用到，但是存储引擎使用age条件过滤了部分需要
--回表的数据(索引下推，5.6以前是需要回表查所有数据然后去server层过滤的)
explain select * from tuser where name like '张%' and age=10; 

--Using index condition; Using where
--在上一条语句的基础上加了一个没有在索引中的条件，所以需要通过存储引擎查出所有符合条件的语句后
--拿到server层再用ismale字段过滤（Using where）
explain select * from tuser where name like '张%' and age=10 and ismale = 1;

--Using where; Using index
--在二级索引里面查到了所有字段，没有回表，但是age字段是在server层过滤，所以使用到了Using where
explain select name,age from tuser where name like '张%' and age=10 ;
```



>   MySQL实战45讲--第五讲评论
>
> 一张表两个字段id, uname,id主键，uname普通索引
> SELECT * FROM test_like WHERE uname LIKE 'j'/ 'j%' / '%j'/ '%j%'
> 模糊查询like后面四种写法都可以用到uname的普通索引
>
> 添加一个age字段
> like后面的'%j'/ '%j%' 这两种情况用不到索引
> 把select * 改为 select id / select uname / select id,uname
> like后面'j'/ 'j%' / '%j'/ '%j%' 这四种情况又都可以用到uname普通索引
>
> 建立uname,age的联合索引
> 模糊查询还是 LIKE 'j'/ 'j%' / '%j'/ '%j%'四种情况
> 其中select id / select uname / select id,uname
> 会用到uname的普通索引
> select * 会用到uname,age的组合索引  
>
> 
>
> 这几个例子真是好，如果把这四个例子理解透了，我想对mysql的索引就理解的差不多了。
> 下面开始解答：
> 1、因为查询的是 * ，会查询所有字段（id,uname）,而二级索引恰恰包含这些数据，又二级索引树比主键索引树小很多，所以直接挨个查询二级索引要比挨个查询主键索引要快的多，故用的是二级索引；
> 2、因为添加了age字段，但是二级索引里面没有age字段，就必须要回主键树查询所有字段（回表过程），所以挨个查询主键索引树，就不走二级索引树了；
> 3、因为建立了联合索引，所以二级索引树里面就包含了所有的字段（id,uname,age），所以就不用搜索主键索引树了；
> 综上：二级索引树小，且又包含了我们所需要的字段，所以就直接用二级索引啦，但是仍然是挨个遍历的。所以这里是和老师说的"用索引"是一个意思。顺便解释下老师说的用索引定位：就是不用搜索整个索引库直接用二分法能快速找到的数据叫用索引定位。
>
> 
>
> 1. like 'j' 或 'j%' 可以使用索引，并且快速定位记录。
> 2. like '%j' 或 '%j%'，只是在二级索引树上遍历查找记录，并不能快速定位（扫描了整棵索引树）。
> 3. 只有 id 和 uname 字段时，上述 4 种 like 查询，uname 索引能满足 id 和 uname 的查询情况，不需要回表，所以选择了使用 uname 的索引树解决问题。
> 4. 添加了 age 但无联合索引 (uname, age) 的情况，如果使用 uname 索引树，需要回表。在 like '%j' 或 '%j%' 直接扫描主键索引树，现象就是没有使用 uname 索引。
> 5. 添加了 age 字段，也添加了 (uname, age) 索引，和第 3 点同理，使用覆盖索引就能满足 select * 的字段查询，不需要回表，因此使用了 (uname, age) 索引树。但是只有 like 'j' 和 'j%'
> 能快速定位记录，而 like '%j' 和 '%j%' 也能使用该索引树，但是不能快速定位，需要顺序遍历。











#### 10.redolog 和change buffer(普通索引用)

​		redo log 与 change buffer(含磁盘持久化) 这2个机制，不同之处在于——优化了整个变更流程的不同阶段。 先不考虑redo log、change buffer机制，简化抽象一个变更(insert、update、delete)流程：

 1、从磁盘读取待变更的行所在的数据页，读取至内存页中。 

2、对内存页中的行，执行变更操作

 3、将变更后的数据页，写入至磁盘中。 

步骤1，涉及 随机 读磁盘IO；

 步骤3，涉及 随机 写磁盘IO；

 Change buffer机制，**缓存二级索引(非唯一)上的更新操作**。优化了步骤1——避免了随机读磁盘IO 

Redo log机制， 优化了步骤3——避免了随机写磁盘IO，将随机写磁盘，优化为了顺序写磁盘(写redo log，确保crash-safe) 

-------------------------------- 在我们mysql innodb中， change buffer机制不是一直会被应用到，仅当待操作的数据页当前不在内存中，需要先读磁盘加载数据页时，change buffer才有用武之地。 redo log机制，为了保证crash-safe，一直都会用到。

 ------------------------------- 有无用到change buffer机制，对于redo log这步的区别在于—— 用到了change buffer机制时，在redo log中记录的本次变更，是记录new change buffer item相关的信息，而不是直接的记录物理页的变更。



当要更新的数据在内存中，命中，直接在内存更新，记录redolog;如果不在，写change buffer，然后记录redolog，此时redolog记录的是change buffer中的改动，所以redolog刷盘时是刷到change buffer的ibdata1,并不会将他直接更新到数据文件（表名.ibd）中，当内存中读入这个页时会将change buffer的更新merge一起到内存中，这时候才算真正更新了数据



merge 的执行流程是这样的：从磁盘读入数据页到内存（老版本的数据页）；从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页；写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。到这里 merge 过程就结束了。这时候，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。

总结：

（1）普通索引与唯一索引，普通索引在更新时速度更快，尽量选普通索引 

（2)  更新之后马上就是查询时，不使用change buffer

   (3)  change buffer更适合普通索引



#### 11.重建表 online DDL

可以使用 alter table A engine=InnoDB 命令来重建表，来减少空洞。在 MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。我给你简单描述一下引入了 Online DDL 之后，重建表的流程：

建立一个临时文件，扫描表 A 主键的所有数据页；

用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；

生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；

临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；

用临时文件替换表 A 的数据文件。

alter 语句在启动的时候需要获取 MDL 写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。为什么要退化呢？为了实现 Online，MDL 读锁不会阻塞增删改操作。那为什么不干脆直接解锁呢？为了保护自己，禁止其他线程对这个表同时做 DDL。而对于一个大表来说，Online DDL 最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个 DDL 过程来说，锁的时间非常短。对业务来说，就可以认为是 Online 的。

需要补充说明的是，上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗 IO 和 CPU 资源的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，我推荐你使用 GitHub 开源的 gh-ost 来做。

根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。所以，我现在问你，如果你有一个 1TB 的表，现在磁盘间是 1.2TB，能不能做一个 inplace 的 DDL 呢？答案是不能。因为，tmp_file 也是要占用临时空间的。

为什么online DDL期间要MDL写锁->读锁->写锁，再开始和临时文件替换表A的过程中，会升级为写锁，这时候其他DML语句执行的时候需要读锁，但是实际申请MDL锁里面是一个队列，而且写锁优先级要高于读锁，如果有人占了写锁，别的session申请不到读锁，会阻塞别人获取读锁，也就是说DML语句执行不了了。防止合并row log或者替换表的时候有 DML操作，这时候仍然会阻塞DML，也就是两次写锁期间是阻塞的。



optimize table、analyze table 和 alter table 这三种方式重建表的区别。这里，我顺便再简单和你解释一下。从 MySQL 5.6 版本开始，

alter table t engine = InnoDB（也就是 recreate）默认的就是上面图 4 的流程了；

analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；

optimize table t 等于 recreate+analyze。



#### 12.间隙锁

间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。 但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。这，也是现在不少公司使用的配置组合。

 举个例子：删除 statement记录的是这个删除的语句，例如： delete from t where age>10 and modified_time<='2020-03-04' limit 1 而row格式记录的是实际受影响的数据是真实删除行的主键id，例如： delete from t where id=3 and age=12 and modified_time='2020-03-05'

我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。

原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。

原则 2：查找过程中访问到的对象才会加锁。

优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。

优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。

~~一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。~~

**跟Oracle 确认过了，唯一索引范围锁的bug在最新的8.0.18已经修复！**

bug实验确认：

```sql
--建表语句
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  `d` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `c` (`c`)
) ENGINE=InnoDB;

insert into t values(0,0,0),(5,5,5),
(10,10,10),(15,15,15),(20,20,20),(25,25,25);

--5.7
--sessionA
 BEGIN;
SELECT * FROM t WHERE id <= 15 FOR UPDATE;
--sessionB
insert into t values(17,17,17);
select * from t where id = 20 for update


--在5.7的情况下是被锁住了，说明将(15，20]也锁住了 说明扫到了20，按道理来说只需要扫描到15 
--而8.0.21可以插入成功

--这里如果把语句改成
--sessionA
 BEGIN;
SELECT * FROM t WHERE id < 15 FOR UPDATE;
--那么加锁范围就只到(10，15]

```







在read-commited隔离级别下，update语句有一个“semi-consistent” read优化，意思是，如果update语句碰到一个已经被锁了的行，会读入最新的版本，然后判断一下是不是满足查询条件，
a)如果不满足，就直接跳过；
b) 如果满足，才进入锁等待



#### 13.mysql刷脏页的四种情况

 1.redo log写满（redo log本质是一个定长的循环队列）

 2.内存写满（淘汰页面） （直接刷脏页是不会动redolog的，等后续应用redolog的时候，会根据LSN 的大小来判断这个页有没有应用到这条log）。

 3.系统空闲时写回 

 4.关闭mysql时写回 

3.4影响较小，1，2影响较大。要尽量避免这种情况，你就要合理地设置 innodb_io_capacity 的值，并且平时要多关注脏页比例，不要让它经常接近 75%。

```sql
--计算脏页比例
 select VARIABLE_VALUE into @a from performance_schema.global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';
 select VARIABLE_VALUE into @b from performance_schema.global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';
 select @a/@b;
```

mysql还有一个比较有趣的刷脏页策略，而 MySQL 中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。而如果使用的是 SSD 这类 IOPS 比较高的设备的话，我就建议你把 innodb_flush_neighbors 的值设置成 0。因为这时候 IOPS 往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少 SQL 语句响应时间。在 MySQL 8.0 中，innodb_flush_neighbors 参数的默认值已经是 0 了。

当内次不足需要淘汰脏页的时候，刷脏页过程不用动redo log文件的。

这个有个额外的保证，是redo log在“重放”的时候，如果一个数据页已经是刷过的，会识别出来并跳过。  



innodb是如何知道一个页是不是脏页?

  每个数据页头部有LSN，8字节，每次修改都会变大。对比这个LSN跟checkpoint 的LSN，比checkpoint小的一定是干净页  

> “内存不够用了，要先将脏页写到磁盘“和“redo log 写满了，要 flush 脏页”可以理解为一个脏页本身占用内存，释放内存需要将脏页写入到磁盘才能释放。而redo log写满只有当redo log对应的脏页flush到磁盘上才能释放对应空间。有几个问题：
> 1、“内存不够用了，要先将脏页写到磁盘“redo log对应的空间会释放嘛？“redo log 写满了，要 flush 脏页”对应的内存页会释放嘛？
> 2、将脏页flush到磁盘上是直接将脏页数据覆盖到对应磁盘上的数据？还是从磁盘上取到数据后取根据redo log记录进行更新后再写入到磁盘？
> 3、redo log是怎么记录对应脏页是否已经flush了？如果断电了重启导致内存丢失，前面几章说通过redo log进行数据恢复那redo log又怎么去释放空间
>
> 
>
>   作者回复: 1. Redolog 的空间是循环使用的，无所谓释放。 对应的内存页会变成干净页。但是等淘汰的时候才会逐出内存
>
> \2. 好问题，前者
>
> \3. 不用记，重启了就从checkpoint 的位置往后扫。 如果已经之前刷过盘的, 不会重复应用redi log。 好问题  



#### 14.mysql怎么知道binlog是完整的？（crash-safe相关）

回答：一个事务的 binlog 是有完整格式的：

statement 格式的 binlog，最后会有 COMMIT；

row 格式的 binlog，最后会有一个 XID event。

另外，在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。所以，MySQL 还是有办法验证事务 binlog 的完整性的。





#### 15.redolog和binlog怎么相关联的？

回答：它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：

如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；

如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。binlog完整提交，不完整则回滚。





#### 16.如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？

针对这个问题可以考虑以下三种方法：

​		1.设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。

​		2.将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。

​		3.将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。

我不建议你把 innodb_flush_log_at_trx_commit 设置成 0。因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启也会丢数据，风险太大。而 redo log 写到文件系统的 page cache 的速度也是很快的，所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样做 MySQL 异常重启时就不会丢数据了，相比之下风险会更小。

你在什么时候会把线上生产库设置成“非双 1”。我目前知道的场景，有以下这些：业务高峰期。一般如果有预知的高峰期，DBA 会有预案，把主库设置成“非双 1”。备库延迟，为了让备库尽快赶上主库。@永恒记忆和 @Second Sight 提到了这个场景。用备份恢复主库的副本，应用 binlog 的过程，这个跟上一种场景类似。批量导入数据的时候。一般情况下，把生产库改成“非双 1”配置，是设置 innodb_flush_logs_at_trx_commit=2、sync_binlog=1000。



#### 17.crash-safe保证的是什么

实际上数据库的 crash-safe 保证的是：

​		如果客户端收到事务成功的消息，事务就一定持久化了；

​		如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了；

​		如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了。



#### 18.mysql 主备切换流程 GTID模式

备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的：

* 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。

* 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。

* 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。

* 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。

* sql_thread 读取中转日志，解析出日志里的命令，并执行。





GTID 模式的启动也很简单，我们只需要在启动一个 MySQL 实例的时候，加上参数 gtid_mode=on 和 enforce_gtid_consistency=on 就可以了。

实例 A’的 GTID 集合记为 set_a，实例 B 的 GTID 集合记为 set_b。接下来，我们就看看现在的主备切换逻辑。我们在实例 B 上执行 start slave 命令，取 binlog 的逻辑是这样的：

​		实例 B 指定主库 A’，基于主备协议建立连接。

​		实例 B 把 set_b 发给主库 A’。

​		实例 A’算出 set_a 与 set_b 的差集，也就是所有存在于 set_a，但是不存在于 set_b 的 GTID 的集合，判断 A’本地是否包含了这个差集需要的所有 binlog 事务。

​				a. 如果不包含，表示 A’已经把实例 B 需要的 binlog 给删掉了，直接返回错误；

​				b. 如果确认全部包含，A’从自己的 binlog 文件里面，找出第一个不在 set_b 的事务，发给 B；

之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行。





#### 19.mysql semi-sync

半同步复制，也就是 semi-sync replication。semi-sync 做了这样的设计：

​		事务提交的时候，主库把 binlog 发给从库；

​		从库收到 binlog 以后，发回给主库一个 ack，表示收到了；

​		主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。

也就是说，如果启用了 semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经收到了这个日志。



#### 20.如何使用join

**原则：小表驱动大表**

Index Nested-Loop Join（NLJ）：能使用被驱动表的索引

Simple Nested-Loop Join： 不能使用被驱动表的索引，全扫（mysql不用）

Block Nested-Loop Join  (BNL): 使用了join_buffer,join_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t1 的所有数据话，策略很简单，就是分段放。放不下会导致被驱动表被全表扫描多次

​	   能不能使用 join 语句？

如果可以使用 Index Nested-Loop Join 算法，也就是说可以用上被驱动表上的索引，其实是没问题的；

如果使用 Block Nested-Loop Join 算法，扫描行数就会过多。尤其是在大表上的 join 操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种 join 尽量不要用。

所以你在判断要不要使用 join 语句时，就是看 explain 结果里面，Extra 字段里面有没有出现“Block Nested Loop”字样。

​		驱动表分段很容易导致innodb的buffer poor将热数据移除加载冷数据，导致Buffer pool hit rate命中率极低，其他请求需要读磁盘，因此系统响应变慢，大部分请求阻塞。

​		还会出现：1. 长期占用DML锁，引发DDL拿不到锁堵慢连接池； 2. SQL执行socket_timeout超时后业务接口重复发起，导致实例IO负载上升出现雪崩；3. 实例异常后，DBA kill SQL因繁杂的回滚执行时间过长，不能快速恢复可用；4. 如果业务采用select *作为结果集返回，极大可能出现网络拥堵，整体拖慢服务端的处理；5. 冷数据污染buffer pool，block nested-loop多次扫描，其中间隔很有可能超过1s，从而污染到lru 头部，影响整体的查询体验。



BNLJ转BKA
方案一：在被驱动表的join字段上添加索引，相当于BNLJ先转INLJ再转BKA。
方案二：不适宜添加索引的情况（查询语句使用频率较低），引入临时表。具体操作步骤如下：
   a. 先根据where过滤被驱动表t2，并将结果存入临时表tmp_t；
   b. 在临时表上为join字段b添加索引；
   c. 让驱动表t1连接临时表tmp_t。
（注意，由于步骤b中需要为临时表创建索引，所以此方案当且仅当tmp_t规模远小于t2时才划算！

mysql 8.0 hash-join
可视为BNLJ进阶，将join_buffer变成Hash表



​		**join语句优化**

​		**Multi-Range Read 优化 (MRR)。这个优化的主要目的是尽量使用顺序读盘。**

​		之前我们提到的回表操作，在非主键索引上，叶节点存储的是主键的id，这个时候要回主键索引一行行查找数据，这个时候其实会造成磁盘的随机读，因为主键索引查出来的时候不一定是有序的，我们无法优化一行行查找这个行为，但是可以通过其他手段将随机读改为顺序读。

​		因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。

这，就是 MRR 优化的设计思路。此时，语句的执行流程变成了这样：

* 根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;

* 将 read_rnd_buffer 中的 id 进行递增排序；

* 排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。

这里，read_rnd_buffer 的大小是由 read_rnd_buffer_size 参数控制的。如果步骤 1 中，read_rnd_buffer 放满了，就会先执行完步骤 2 和 3，然后清空 read_rnd_buffer。之后继续找索引 a 的下个记录，并继续循环。另外需要说明的是，如果你想要稳定地使用 MRR 优化的话，设置`set optimizer_switch="mrr_cost_based=off"`。（官方文档的说法，是现在的优化器策略，判断消耗的时候，会更倾向于不使用 MRR，把 mrr_cost_based 设置为 off，就是固定使用 MRR 了。）

```sql
set optimizer_switch="mrr_cost_based=on/off"
```

MRR 能够提升性能的核心在于，这条查询语句在索引 a 上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键 id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。



​		**BKA(Batched Key Access)算法优化**,如果要使用 BKA 优化算法的话，你需要在执行 SQL 语句之前，先设置

```sql
set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
```







#### 21.MySQL 什么时候会使用内部临时表？

* 如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果；

* join_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构；

* 如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union 需要用到唯一索引约束， group by 还需要用到另外一个字段来存累积计数。

group by 的几种实现算法，从中可以总结一些使用的指导原则：

* 如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null；

* 尽量让 group by 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary 和 Using filesort；

* 如果 group by 需要统计的数据量不大，尽量只使用内存临时表；

* 也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表；如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果。



#### 22.在什么场景下自增主键可能不连续？

1：唯一键冲突
2：事务回滚
3：自增主键的批量申请



#### 23.mysql 权限

![mysql权限](http://ww1.sinaimg.cn/large/d1885ed1ly1g0ab2twmjaj21gs0js78u.jpg)





#### 24.为什么不要使用长事务？

* 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。（基于mvcc分析）在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。
* 长事务还占用锁资源
* 大事务造成主备延迟。因为主库上必须等事务执行完成才会写入 binlog，再传给备库。所以，如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10 分钟



怎么排查长事务？

你可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。记录了所有正在运行的事务信息

select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60

注意：事务在第一个sql启动，后边有提到 不区分select update

**begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 start transaction with consistent snapshot 这个命令。**

[undo_redo](chrome-extension://oemmndcbldboiebfnladdacbdfmadadm/http://bos.itdks.com/b2c20ce5c11940b6b0a4e98547f67664.pdf)

监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；

Percona 的 pt-kill 这个工具不错，推荐使用；

在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；

如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。



#### 25.死锁

当出现死锁以后，有两种策略：

* 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。

> 在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。
>
> 但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。所以我们一般使用死锁检测。

* 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。

> innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。死锁检测要耗费大量的 CPU 资源





#### 26.查询长时间不返回 （mysql45讲 19讲）

可以使用show processlist查看当前语句处于什么状态





#### 27.如果业务确定不需要间隙锁或者可重复读隔离级别建议隔离级别设置RC，binlog格式设置为row



#### 28.mvcc

MySQL  InnoDB存储引擎，实现的是基于多版本的并发控制协议——MVCC  (Multi-Version Concurrency  Control)(注：与MVCC相对的，是基于锁的并发控制，Lock-Based  Concurrency Control)。MVCC最大的好处，相信也是耳熟能详：读不加锁，读写不冲突。在读多些少的OLTP应用中，读写不冲突是非常重要的，极大的增加了系统的并发性能，这也是为什么现阶段，几乎所有的RDBMS，都支持了MVCC。

在MVCC并发控制中，读操作可以分成两类：快照读(snapshot read)与当前读(current read)。

快照读，读取的是记录的可见版本(有可能是历史版本)，不用加锁。

当前读，读取的是记录的最新版本，并且，当前读返回的记录，都会加上锁，保证其他事务不会再并发修改这条记录。



#### 29.mysql主库高可用

mysql主从+keepalived/heatbeat
HMA/MMM
ZK



#### 30.线上慢查询发现索引没建立好 

导致慢查询的第一种可能是，索引没有设计好。这种场景一般就是通过紧急创建索引来解决。

MySQL 5.6 版本以后，创建索引都支持 Online DDL 了，对于那种高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行 alter table 语句。比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库 A、备库 B，这个方案的大致流程是这样的：

在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行 alter table 语句加上索引；执

行主备切换；这时候主库是 B，备库是 A。

在 A 上执行 set sql_log_bin=off，然后执行 alter table 语句加上索引。

**45讲22讲**

























1. 使用 show index from table_name 命令，查看表索引的基数 
2.  使用 analyze table table_name 命令，重新统计索引信息,解决采样导致的扫描行数出错的问题

3. 查看表占用硬盘空间大小的SQL语句如下：(用M做展示单位)

```sql
SELECT

concat(round(sum(DATA_LENGTH/ 1024),2),'M')ASsize

FROM information_schema.TABLES

WHERE table_schema= '数据库名'AND table_name= '表名';

```



 释放表的磁盘空间

```sql
optimize table table_name
```



3.查询innodb设置的io刷脏页的能力

```sql
show global variables like 'innodb_io_capacity'  
```



4.查看数据库脏页比例

```sql
 select VARIABLE_VALUE into @a from performance_schema.global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';
 select VARIABLE_VALUE into @b from performance_schema.global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';
 select @a/@b;
```

5.在 InnoDB 中，innodb_flush_neighbors 参数控制刷脏页是否'连坐'，如果硬盘为SSD建议把该参数设置为0，关掉连坐行为。mysql8.0默认为0



6.确定一个排序是否使用了临时文件,这个方法是通过查看 OPTIMIZER_TRACE 的结果来确认的，你可以从 number_of_tmp_files 中看到是否使用了临时文件。number_of_tmp_files 表示的是，排序过程中使用的临时文件数，如果 sort_buffer_size 超过了需要排序的数据量的大小，number_of_tmp_files 就是 0，表示排序可以直接在内存中完成。否则就需要放在临时文件中排序。sort_buffer_size 越小，需要分成的份数越多，number_of_tmp_files 的值就越大。

   sort_buffer是在server层，5.7好像是默认256K（On Linux, there are thresholds of 256KB and 2MB）

​	sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。

​	max_length_for_sort_data，默认1024个字节（5.7，8默认值为4096，但我看官网这个参数已经被废弃了，之前用来决定使用哪种filesort算法），是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。

[Mysql中单路排序和双路排序详解](https://blog.csdn.net/m0_45406092/article/details/112609434)

```sql

/* 打开optimizer_trace，只对本线程有效 */
SET optimizer_trace='enabled=on'; 

/* @a保存Innodb_rows_read的初始值 */
select VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';

/* 执行语句 */
select city, name,age from t where city='杭州' order by name limit 1000; 

/* 查看 OPTIMIZER_TRACE 输出 */
SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G

/* @b保存Innodb_rows_read的当前值 */
select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';

/* 计算Innodb_rows_read差值 */
select @b-@a;
```

sortbuffer全字段排序（单路排序？）

![全字段排序（单路排序）.jpg](http://ww1.sinaimg.cn/large/0072fULUgy1gr56a8f1s8j60vq0nsq5x02.jpg)

sortbuffer rowId排序（双路排序？）

![rowId排序（双路排序）.jpg](http://ww1.sinaimg.cn/large/0072fULUgy1gr56c22ci1j60vq0nsjun02.jpg)

7.确定索引的选择性

```sql
count(distinctleft(列名, 索引长度))/count(*)
```



8.为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值：		设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;

​		设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；

​		设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。

InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。



9.binlogwrite 和 fsync 的时机，是由参数 sync_binlog 控制的：

​		sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；

​		sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；

​		sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。

如果你想提升 binlog 组提交的效果，可以通过设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 来实现。

binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;

binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。



一般情况下，把生产库改成“非双 1”配置，是设置 innodb_flush_logs_at_trx_commit=2、sync_binlog=1000。



10. 查看binlog的格式 

```sql
show variables like '%binlog_format%';
```



11.windows下的mysql配置开启binlog,修改my.ini文件，在[mysqld]下面添加

log_bin=mysql-bin
binlog-format=ROW
server-id=1

binlog的三种格式，statement,记录数据库原句，有可能导致，主备所选择的索引不一致，导致主备数据不一致。row，binlog log记录的是操作的字段值，根据binlog_row_image 的默认配置是 FULL包括操作行为的所有字段值，binlog_row_image 设置为 MINIMAL，则会记录必须的字段,一般设置为row，可以根据binlog文件做其他操作，比如在误删除一行数据时，可以做insert，恢复数据

重启mysql后会发现data目录下会多两个文件mysql-bin.000001，mysql-bin.index

查看binlog日志是否开启

```sql
show variables like '%log_bin%'

log_bin	OFF
log_bin_basename	
log_bin_index	
log_bin_trust_function_creators	OFF
log_bin_use_v1_row_events	OFF
sql_log_bin	ON

--查询binlog日志
show binlog events in 'mysql-bin.000001';

mysql-bin.000001	4	Format_desc	1	123	Server ver: 5.7.27-log, Binlog ver: 4
mysql-bin.000001	123	Previous_gtids	1	154	
mysql-bin.000001	154	Anonymous_Gtid	1	219	SET @@SESSION.GTID_NEXT= 'ANONYMOUS'
mysql-bin.000001	219	Query	1	296	BEGIN
mysql-bin.000001	296	Table_map	1	347	table_id: 115 (employees.f)
mysql-bin.000001	347	Update_rows	1	409	table_id: 115 flags: STMT_END_F
mysql-bin.000001	409	Xid	1	440	COMMIT /* xid=71 */

--使用mysqlbinlog查看详细日志
mysqlbinlog -vv mysql-bin.000001 --start-position=154

$ mysqlbinlog -vv mysql-bin.000001 --start-position=154
/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;
/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;
DELIMITER /*!*/;
# at 4
#210430  9:20:11 server id 1  end_log_pos 123 CRC32 0x4a1b8737  Start: binlog v 4, server v 5.7.27-log created 210430  9:20:11 at startup
# Warning: this binlog is either in use or was not closed properly.
ROLLBACK/*!*/;     
BINLOG '
S1uLYA8BAAAAdwAAAHsAAAABAAQANS43LjI3LWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAABLW4tgEzgNAAgAEgAEBAQEEgAAXwAEGggAAAAICAgCAAAACgoKKioAEjQA
ATeHG0o=
'/*!*/;
# at 154
#210430  9:25:27 server id 1  end_log_pos 219 CRC32 0x6ca329bd  Anonymous_GTID  last_committed=0        sequence_number=1       rbr_only=yes
/*!50718 SET TRANSACTION ISOLATION LEVEL READ COMMITTED*//*!*/;
SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;
# at 219
#210430  9:25:27 server id 1  end_log_pos 296 CRC32 0x8bf08bef  Query   thread_id=4     exec_time=0     error_code=0
SET TIMESTAMP=1619745927/*!*/;
SET @@session.pseudo_thread_id=4/*!*/;
SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;
SET @@session.sql_mode=1344274432/*!*/;
SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;
/*!\C utf8mb4 *//*!*/;
SET @@session.character_set_client=45,@@session.collation_connection=45,@@session.collation_server=8/*!*/;
SET @@session.lc_time_names=0/*!*/;
SET @@session.collation_database=DEFAULT/*!*/;
BEGIN
/*!*/;
# at 296
#210430  9:25:27 server id 1  end_log_pos 347 CRC32 0xfa6d8112  Table_map: `employees`.`f` mapped to number 115
# at 347
#210430  9:25:27 server id 1  end_log_pos 409 CRC32 0x02bf3edb  Update_rows: table id 115 flags: STMT_END_F

BINLOG '
h1yLYBMBAAAAMwAAAFsBAAAAAHMAAAAAAAEACWVtcGxveWVlcwABZgADAwMDAAYSgW36
h1yLYB8BAAAAPgAAAJkBAAAAAHMAAAAAAAEAAgAD///4AAAAAAAAAAAAAAAA+AAAAAADAAAAAAAA
ANs+vwI=
'/*!*/;
### UPDATE `employees`.`f`
### WHERE
###   @1=0 /* INT meta=0 nullable=0 is_null=0 */
###   @2=0 /* INT meta=0 nullable=1 is_null=0 */
###   @3=0 /* INT meta=0 nullable=1 is_null=0 */
### SET
###   @1=0 /* INT meta=0 nullable=0 is_null=0 */
###   @2=3 /* INT meta=0 nullable=1 is_null=0 */
###   @3=0 /* INT meta=0 nullable=1 is_null=0 */
# at 409
#210430  9:25:27 server id 1  end_log_pos 440 CRC32 0x00de6e12  Xid = 71
COMMIT/*!*/;
SET @@SESSION.GTID_NEXT= 'AUTOMATIC' /* added by mysqlbinlog */ /*!*/;
DELIMITER ;
# End of log file
/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;
/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/;
```

binlog 来恢复数据的标准做法是，用 mysqlbinlog 工具解析出来，然后把解析结果整个发给 MySQL 执行。类似下面的命令：

mysqlbinlog master.000001  --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;

这个命令的意思是，将 master.000001 文件里面从第 2738 字节到第 2973 字节中间这段内容解析出来，放到 MySQL 去执行。



12.查看和连接时间有关的MySQL系统变量

```sql
 show variables like '%timeout%'
 
 
 connect_timeout	10
delayed_insert_timeout	300
have_statement_timeout	YES
innodb_flush_log_at_timeout	1
innodb_lock_wait_timeout	50
innodb_rollback_on_timeout	OFF
interactive_timeout	28800
lock_wait_timeout	31536000
net_read_timeout	30
net_write_timeout	60
rpl_stop_slave_timeout	31536000
slave_net_timeout	60
wait_timeout	28800
```

​	其中wait_timeout就是负责超时控制的变量，其时间为长度为28800s，就是8个小时，那么就是说MySQL的服务会在操作间隔8小时后断开，需要再次重连。

  interactive_timeout：服务器关闭交互式连接前等待活动的秒数。交互式客户端定义为在mysql_real_connect()中使用CLIENT_INTERACTIVE选项的客户端。又见wait_timeout 
    wait_timeout:服务器关闭非交互连接之前等待活动的秒数。在线程启动时，根据全局wait_timeout值或全局interactive_timeout值初始化会话wait_timeout值，取决于客户端类型(由mysql_real_connect()的连接选项CLIENT_INTERACTIVE定义)，又见interactive_timeout 



13.innodb buffer pool size

```sql
SELECT @@innodb_buffer_pool_size/1024/1024/1024;
show variables like 'innodb_buffer_pool%';
```



13.change buffer

```sql
show variables like 'innodb_change%';
innodb_change_buffer_max_size	--25 默认是25，即缓冲池(innodb buffer pool)的1/4。最大可设置为50,采用默认即可
innodb_change_buffering	all --默认是all支持所有DML操作
```





[MySQL explain详解](https://zhuanlan.zhihu.com/p/114182767)

[一张图彻底搞懂MySQL的 explain](https://segmentfault.com/a/1190000021458117)

[MySQL索引背后的数据结构及算法原理](http://blog.codinglabs.org/articles/theory-of-mysql-index.html)

[不要用 SELECT *](https://mp.weixin.qq.com/s?__biz=MzAxNDMwMTMwMw==&mid=2247518736&idx=3&sn=681243c05b9d5e514753d9c6198bd2e4&chksm=9b97ab08ace0221e89babc6740f2ca4c1e1905c45ec615435c8400997ecb8cb2f385de3ef158&mpshare=1&scene=24&srcid=032054u5rYxFksxE7XOj4N5C&sharer_sharetime=1616211731550&sharer_shareid=232a5434dda7f9bc9ee0a06a8085ff95#rd)

[我说 SELECT COUNT(*) 会造成全表扫描，面试官让我回去等通知](https://www.jianshu.com/p/8db16b21910e) 

[我叫小M，立志建立MySQL帝国](https://mp.weixin.qq.com/s?__biz=MzkxNTE3NjQ3MA==&mid=2247488749&idx=1&sn=3bab1201536d4f500a2d0a824c109be2&chksm=c1627994f615f082f87813cb4a7b7d1199585b3b676cea57c99914122b4b33602488f1952170&mpshare=1&scene=1&srcid=0331HLYBZSdzjrDj9F61I8BA&sharer_sharetime=1617180026750&sharer_shareid=08dcc952c1dbf40692e2eadee7b24ea2&key=01e0afdaa229c2675097a90ed20e732d0379ba510e1704b9875d3c4ad989a8807a99c404e01acf40647ecd6ca5c808e09457b04d5ddf9493ae82a78f97bfff07e64509ab8c7c6b6ae751cc0bb1065eae8cd0e7770a90f99e1a261296c716ac99ce2222604678683278612bdd1432d42833506e1c3c6cced88a1e8c229b2cf02e&ascene=1&uin=MTgxNTEwNTUxMw%3D%3D&devicetype=Windows+10+x64&version=62090529&lang=zh_CN&exportkey=AazLWj7bREUc%2FqgTvG3iofw%3D&pass_ticket=4xeKDq6zXZ5k6vdsFjTOLcHvfCVu%2BspCKcbKDRq6gkyVTMAw0ivTQPIciP3hD3XG&wx_header=0)

[1分钟了解MyISAM与InnoDB的索引差异](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961494&idx=1&sn=34f1874c1e36c2bc8ab9f74af6546ec5&chksm=bd2d0d4a8a5a845c566006efce0831e610604a43279aab03e0a6dde9422b63944e908fcc6c05&scene=21#wechat_redirect)

[MySQL 避免行锁升级为表锁——使用高效的索引](https://blog.csdn.net/wangen2010/article/details/100878916?utm_medium=distribute.pc_relevant_bbs_down.none-task-blog-baidujs-1.nonecase&depth_1-utm_source=distribute.pc_relevant_bbs_down.none-task-blog-baidujs-1.nonecase)

[MySQL ICP（Index Condition Pushdown）特性](https://www.cnblogs.com/Terry-Wu/p/9273177.html)

[MySQL的MVCC及实现原理](https://blog.csdn.net/qq_35623773/article/details/106107909)

[mysql临键锁](https://www.jianshu.com/p/f7142e39f455)

[了解常见的锁类型](https://www.aneasystone.com/archives/2017/11/solving-dead-locks-two.html)

[何登成的《MySQL 加锁处理分析》](https://github.com/hedengcheng/tech)

[MySQL8.0 新特性 Hash Join](https://www.cnblogs.com/cchust/p/11961851.html)

[mysql官网-配置参数](https://dev.mysql.com/doc/refman/8.0/en/server-option-variable-reference.html)

[mysql undo log位置_MySQL 日志(redo log 和 undo log) 都是什么鬼？](https://blog.csdn.net/weixin_42366095/article/details/113435651)

[mysql MDL读写锁阻塞，以及online ddl造成的“插队”现象](https://blog.csdn.net/q2878948/article/details/96430129)





[MySQL 性能需要关注的参数](http://blog.itpub.net/29654823/viewspace-2157149/)

[MySQL innodb引擎的事务执行过程](http://blog.itpub.net/29654823/viewspace-2153187/)

